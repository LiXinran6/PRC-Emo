
EP=4
BN=2
CPE=1
LR_SCHEDULER="linear"
LR=3e-4
LORA_R=32
TOPK=0
WINDOW=5


# spdescV2: Generate speaker features  
# default: Generate nothing  
# ImplicitEmotion: Use implicit emotion labels and their descriptions  
# ImplicitEmotion_V2: Use explicit emotion descriptions and implicit emotion descriptions, generated by Qwen2.5  
# ImplicitEmotion_V2_byQwen3_14b: Use explicit emotion descriptions and implicit emotion descriptions (30–50 words), generated by Qwen3-14b  
# ImplicitEmotion_V3: Replace SurfaceEmotion with ExplicitEmotion (30–50 words), generated by Qwen3-14b with a window size of 10  
# spdescV3: 100-word background summary and speaker summary, generated by Qwen14b  
# spdescV4: 250-word background summary and speaker summary, generated by Qwen14b  
# spdescV5: 250-word speaker personality description, generated by Qwen14b  
# spdescV6: 100-word speaker personality description, generated by Qwen14b

#spdescV2：生成说话人特征
#default：啥也不生成
#ImplicitEmotion：使用隐性情绪标签以及其描述
#ImplicitEmotion_V2：使用显性情绪描述和隐性情绪描述。通过Qwen2.5
#ImplicitEmotion_V2_byQwen3_14b：使用显性情绪描述和隐性情绪描述(30-50词)。通过Qwen3-14b
#ImplicitEmotion_V3：替换SurfaceEmotion为ExplicitEmotion(30-50词)。通过Qwen3-14b，窗口为10
#spdescV3:100词的背景概要和说话人概要，Qwen14b
#spdescV4:250词的背景概要和说话人概要，Qwen14b
#spdescV5：250词的说话人性格，Qwen14b
#spdescV6：100词的说话人性格，Qwen14b

PROMPT_TYPE="ImplicitEmotion_V3" # spdescV2 | default | ImplicitEmotion | ImplicitEmotion_V2 | ImplicitEmotion_V2_byQwen3_14b | ImplicitEmotion_V3 | spdescV3 ｜spdescV6
MODEL_ID="/usr/2Tusr/llm/Qwen2.5-7B-Instruct" # for iemocap. please switch to your own model path
#MODEL_ID="/usr/2Tusr/llm/Qwen3-8B" # for meld. please switch to your own model path
DATANAME="iemocap"   # iemocap | meld 
EXTRACT_PROMTING_LLM_ID="Qwen3-14B"
MAX_SEQ_LEN=2048 
MAX_STEPS=-1
EVAL_DELAY=100000


IFS='/' read -ra ADDR <<< "$MODEL_ID"
MODEL_ID_0=${ADDR[1]}

for seed in 42 43 44 45 46;
do 
python ./src/ft_llm_cl.py  --do_eval_dev --do_eval_test --do_train --curriculum --bucket_number ${BN} \
 --base_model_id $MODEL_ID --curriculum_update_epochs ${CPE}\
 --ft_model_id  ${DATANAME}_${MODEL_ID_0}_ep${EP}_step${MAX_STEPS}_lrs-${LR_SCHEDULER}${LR}_${TOPK}shot_r${LORA_R}_w${WINDOW}_${PROMPT_TYPE}_seed${seed}_L${MAX_SEQ_LEN}_llmdesc${EXTRACT_PROMTING_LLM_ID}_ED${EVAL_DELAY} \
 --lr_scheduler $LR_SCHEDULER --lr $LR   --lora_r $LORA_R --max_steps $MAX_STEPS --epoch ${EP} \
 --kshot $TOPK --window $WINDOW --data_name $DATANAME --prompting_type ${PROMPT_TYPE} --extract_prompting_llm_id $EXTRACT_PROMTING_LLM_ID \
 --re_gen_data --seed $seed  --max_seq_len $MAX_SEQ_LEN --eval_delay $EVAL_DELAY  --data_folder ./data/

done

wait

